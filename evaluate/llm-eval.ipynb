{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"google-cloud-aiplatform>=1.38\" vertexai\n",
    "#TODO: gcloud auth application-default login to authenticate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_root_dir = '/home/watson_chua/efs/axolotl/data/predictions/hansard/'\n",
    "llama_predictions_path = predictions_root_dir + \"llama3_8b_lora.jsonl\"\n",
    "gemma_predictions_path = predictions_root_dir + \"gemma2_9b_lora.jsonl\"\n",
    "gpt4_predictions_path, out_subdir = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc.jsonl\", 'gpt4_normal'\n",
    "# gpt4_predictions_path, out_subdir = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc_concise.jsonl\", 'gpt4_concise'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(llama_predictions_path, 'r') as f:\n",
    "    llama_lines = f.readlines()\n",
    "\n",
    "with open(gemma_predictions_path, 'r') as f:\n",
    "    gemma_lines = f.readlines()\n",
    "\n",
    "with open(gpt4_predictions_path, 'r') as f:\n",
    "    gpt4_lines = f.readlines()\n",
    "\n",
    "llama_lines = [json.loads(l) for l in llama_lines]\n",
    "gemma_lines = [json.loads(l) for l in gemma_lines]\n",
    "gpt4_lines = [json.loads(l) for l in gpt4_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 304, 304)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_lines), len(gemma_lines), len(gpt4_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation': 'As at end-January 2024, there were 101,464 persons who did not vote in the last Presidential election but have since applied to restore their names to the Registers of Electors. All such applications have been approved after being verified by the Elections Department.',\n",
       " 'input': \"<|start_header_id|>system<|end_header_id|>You are a public servant. Your task is to reply to a parliamentary question given a list of supporting points.<|eot_id|><|start_header_id|>user<|end_header_id|>\\nQuestion:Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.\\n\\nSupporting points: **Title: Applications to Restore Names to Registers of Electors**\\n\\n**Executive Summary:**\\n\\nAs of the end of January 2024, a total of 101,464 non-voters from the 2023 Presidential Election have successfully applied to restore their names to the Registers of Electors. This report details the background, process, and implications of these applications, with a focus on ensuring continued electoral engagement and upholding democratic principles.\\n\\n**Background:**\\n\\nThe 2023 Presidential Election saw a significant number of eligible voters abstaining from casting their votes. Consequently, their names were removed from the Registers of Electors in accordance with established electoral regulations. However, recognizing the importance of inclusive participation in democratic processes, the Elections Department provided a mechanism for non-voters to restore their names to the registers.\\n\\n**Application Process:**\\n\\nThe process to restore names to the Registers of Electors was designed to be straightforward and accessible. Non-voters could submit their applications through various channels, including:\\n1. **Online Portal:** A dedicated section on the Elections Department's website allowed individuals to complete and submit their applications electronically.\\n2. **In-Person Submissions:** Local electoral offices across the country were equipped to handle in-person applications, ensuring access for individuals without reliable internet access.\\n3. **Mail-In Applications:** For added convenience, applicants could also restore their names via postal mail by sending completed forms to their respective electoral offices.\\n\\n**Volume of Applications:**\\n\\nBy the end of January 2024, a total of 101,464 individuals had applied to have their names restored. This significant number reflects a robust response from the public, underscoring the desire among citizens to re-engage with the electoral process. The breakdown of applications received through different channels is as follows:\\n- **Online Portal:** 67,892 applications\\n- **In-Person Submissions:** 22,710 applications\\n- **Mail-In Applications:** 10,862 applications\\n\\n**Approval and Verification:**\\n\\nAll 101,464 applications were meticulously reviewed by the Elections Department. The verification process ensured that each applicant met the criteria for restoration, including:\\n- **Verification of Identity:** Confirming the identity of applicants to prevent fraudulent submissions.\\n- **Eligibility Check:** Ensuring that applicants were eligible voters in the 2023 Presidential Election and had not been disqualified for other reasons.\\n- **Data Accuracy:** Cross-referencing application details with existing records to maintain the integrity of the Registers of Electors.\\n\\nUpon successful verification, all applications were approved, and the names of the applicants were restored to the Registers of Electors. This meticulous approach guarantees the reliability and accuracy of the electoral registers.\\n\\n**Implications:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors has several significant implications:\\n1. **Enhanced Voter Engagement:** The substantial number of restored names reflects a renewed commitment among citizens to participate in future elections, thereby strengthening democratic engagement.\\n2. **Inclusivity:** The accessible application process ensured that individuals from diverse backgrounds had the opportunity to restore their names, promoting inclusivity in the electoral process.\\n3. **Administrative Efficiency:** The Elections Department's efficient handling of the applications demonstrates its capability to manage large volumes of requests while maintaining accuracy and integrity.\\n4. **Public Trust:** The transparent and successful restoration process fosters public trust in the electoral system, reinforcing the legitimacy of future elections.\\n\\n**Conclusion:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors is a testament to the commitment of both the Elections Department and the citizens to uphold democratic values. The robust response from non-voters highlights the importance of accessible and inclusive electoral processes. Moving forward, continued efforts to engage and educate the electorate will be crucial in maintaining a vibrant and participatory democracy.\\n\\n**Recommendations:**\\n\\nTo build on this success, the following recommendations are proposed:\\n1. **Ongoing Public Awareness Campaigns:** Continuously educate the public on the importance of voting and the process for restoring names to the Registers of Electors.\\n2. **Enhanced Accessibility:** Further streamline the application process, particularly for online submissions, to accommodate an even broader segment of the population.\\n3. **Regular Updates:** Periodically update the public on the status of the Registers of Electors and any changes to the application process.\\n4. **Feedback Mechanism:** Implement a feedback mechanism to gather insights from applicants on their experience, enabling continuous improvement of the process.\\n\\nBy implementing these recommendations, we can ensure that the electoral system remains robust, inclusive, and reflective of the will of the people.\\n\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_lines[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_lines[0]['input'].split(\"<|end_header_id|>\\nQuestion:\", maxsplit=1)[-1].split(\"\\n\\nSupporting points:\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_questions = [q['input'].split(\"<|end_header_id|>\\nQuestion:\", maxsplit=1)[-1].split(\"\\n\\nSupporting points:\")[0] for q in llama_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(gpt4_lines):\n",
    "    if l['question'] not in llama_questions:\n",
    "        print(i, l['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_gpt4 = pd.DataFrame(gpt4_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated = df_gpt4[df_gpt4['question'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4_deduplicated = df_gpt4.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>summary_points</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>question_speaker</th>\n",
       "      <th>answer_speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>filename</th>\n",
       "      <th>hypothetical_document</th>\n",
       "      <th>date</th>\n",
       "      <th>gpt4_answer_by_hy_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[101,464 non-voters from the 2023 Presidential...</td>\n",
       "      <td>101,464 non-voters from the 2023 Presidential ...</td>\n",
       "      <td>Applications to Restore Names to Registers of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chan Chun Sing (for the Prime Minister)</td>\n",
       "      <td>Mr Leong Mun Wai asked the Prime Minister (a) ...</td>\n",
       "      <td>Mr Chan Chun Sing (for the Prime Minister): As...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Applications to Restore Names to Regi...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>As of the end of January 2024, a total of 101,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[From 2021 to 2023, over 23,300 companies obta...</td>\n",
       "      <td>From 2021 to 2023, over 23,300 companies obtai...</td>\n",
       "      <td>Applications under Enterprise Financing Scheme</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Liang Eng Hwa</td>\n",
       "      <td>Mr Gan Kim Yong</td>\n",
       "      <td>Mr Liang Eng Hwa asked the Minister for Trade ...</td>\n",
       "      <td>Mr Gan Kim Yong: From 2021 to 2023, over 23,30...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Applications under Enterprise Financi...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>From 2021 to 2023, over 23,300 companies have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[About 36,400 companies have received support ...</td>\n",
       "      <td>About 36,400 companies have received support u...</td>\n",
       "      <td>Applications for Productivity Solutions Grant ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Liang Eng Hwa</td>\n",
       "      <td>Mr Gan Kim Yong</td>\n",
       "      <td>Mr Liang Eng Hwa asked the Minister for Trade ...</td>\n",
       "      <td>Mr Gan Kim Yong: In the last three years, abou...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>### Applications for Productivity Solutions Gr...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Over the last three years, approximately 36,40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[Schools have autonomy to decide the end times...</td>\n",
       "      <td>Schools have autonomy to decide the end times ...</td>\n",
       "      <td>Time Guidelines for Schools to Cease Co-curric...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chan Chun Sing</td>\n",
       "      <td>Mr Leong Mun Wai asked the Minister for Educat...</td>\n",
       "      <td>Mr Chan Chun Sing: Schools have the autonomy t...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Time Guidelines for Schools to Cease ...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Yes, there are overarching guidelines for scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[Rail operators have improved track design and...</td>\n",
       "      <td>Rail operators have improved track design and ...</td>\n",
       "      <td>Mitigation Measures to Reduce Noise from Railw...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chee Hong Tat</td>\n",
       "      <td>Mr Leong Mun Wai asked the Minister for Transp...</td>\n",
       "      <td>Over the years, rail operators have improved t...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Report: Mitigation Measures to Reduce Noise ...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>**Reply:**\\n\\nMr Speaker,\\n\\nTo address the no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status reference_answer  \\\n",
       "0  answered                    \n",
       "1  answered                    \n",
       "2  answered                    \n",
       "3  answered                    \n",
       "4  answered                    \n",
       "\n",
       "                                      summary_points  \\\n",
       "0  [101,464 non-voters from the 2023 Presidential...   \n",
       "1  [From 2021 to 2023, over 23,300 companies obta...   \n",
       "2  [About 36,400 companies have received support ...   \n",
       "3  [Schools have autonomy to decide the end times...   \n",
       "4  [Rail operators have improved track design and...   \n",
       "\n",
       "                                              points  \\\n",
       "0  101,464 non-voters from the 2023 Presidential ...   \n",
       "1  From 2021 to 2023, over 23,300 companies obtai...   \n",
       "2  About 36,400 companies have received support u...   \n",
       "3  Schools have autonomy to decide the end times ...   \n",
       "4  Rail operators have improved track design and ...   \n",
       "\n",
       "                                               title subtitle  \\\n",
       "0  Applications to Restore Names to Registers of ...     None   \n",
       "1     Applications under Enterprise Financing Scheme     None   \n",
       "2  Applications for Productivity Solutions Grant ...     None   \n",
       "3  Time Guidelines for Schools to Cease Co-curric...     None   \n",
       "4  Mitigation Measures to Reduce Noise from Railw...     None   \n",
       "\n",
       "   question_speaker                              answer_speaker  \\\n",
       "0  Mr Leong Mun Wai  Mr Chan Chun Sing (for the Prime Minister)   \n",
       "1  Mr Liang Eng Hwa                             Mr Gan Kim Yong   \n",
       "2  Mr Liang Eng Hwa                             Mr Gan Kim Yong   \n",
       "3  Mr Leong Mun Wai                           Mr Chan Chun Sing   \n",
       "4  Mr Leong Mun Wai                            Mr Chee Hong Tat   \n",
       "\n",
       "                                            question  \\\n",
       "0  Mr Leong Mun Wai asked the Prime Minister (a) ...   \n",
       "1  Mr Liang Eng Hwa asked the Minister for Trade ...   \n",
       "2  Mr Liang Eng Hwa asked the Minister for Trade ...   \n",
       "3  Mr Leong Mun Wai asked the Minister for Educat...   \n",
       "4  Mr Leong Mun Wai asked the Minister for Transp...   \n",
       "\n",
       "                                              answer            filename  \\\n",
       "0  Mr Chan Chun Sing (for the Prime Minister): As...  sitting_2024-02-29   \n",
       "1  Mr Gan Kim Yong: From 2021 to 2023, over 23,30...  sitting_2024-02-29   \n",
       "2  Mr Gan Kim Yong: In the last three years, abou...  sitting_2024-02-29   \n",
       "3  Mr Chan Chun Sing: Schools have the autonomy t...  sitting_2024-02-29   \n",
       "4  Over the years, rail operators have improved t...  sitting_2024-02-29   \n",
       "\n",
       "                               hypothetical_document                 date  \\\n",
       "0  **Title: Applications to Restore Names to Regi...  2024-02-29 00:00:00   \n",
       "1  **Title: Applications under Enterprise Financi...  2024-02-29 00:00:00   \n",
       "2  ### Applications for Productivity Solutions Gr...  2024-02-29 00:00:00   \n",
       "3  **Title: Time Guidelines for Schools to Cease ...  2024-02-29 00:00:00   \n",
       "4  **Report: Mitigation Measures to Reduce Noise ...  2024-02-29 00:00:00   \n",
       "\n",
       "                               gpt4_answer_by_hy_doc  \n",
       "0  As of the end of January 2024, a total of 101,...  \n",
       "1  From 2021 to 2023, over 23,300 companies have ...  \n",
       "2  Over the last three years, approximately 36,40...  \n",
       "3  Yes, there are overarching guidelines for scho...  \n",
       "4  **Reply:**\\n\\nMr Speaker,\\n\\nTo address the no...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4_deduplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_predictions = df_gpt4_deduplicated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_predictions['llama3_answer'] = [l['generation']  for l in llama_lines]\n",
    "df_all_predictions['gemma2_answer'] = [l['generation']  for l in gemma_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root_dir = '/home/watson_chua/efs/axolotl/data/evaluations/hansard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_predictions.to_csv(output_root_dir + out_subdir + '/consolidated_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root_dir = '/home/watson_chua/efs/axolotl/data/evaluations/hansard/'\n",
    "subdir = 'gpt4_normal'\n",
    "# subdir = 'gpt4_concise'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_all_predictions = pd.read_csv(output_root_dir + subdir + '/consolidated_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "project_id = \"gvt0031-gcp-152-govtext-ds\"\n",
    "\n",
    "vertexai.init(project=project_id, location=\"asia-southeast1\")\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_three_way_template = \"\"\"Given the following question, context, and three different answers a), b) and c), assess the answer based on the following criteria: \n",
    " 1) factual correctness according to the context\n",
    " 2) similarity to model answer\n",
    " 3) conciseness\n",
    " \n",
    "Respond in JSON whether answer a), b), or c) is the better answer and state your reason using the following schema:\n",
    "\n",
    "{{\"winner\": a, b, or c,\n",
    "\"reason\": reason it is the better answer}}\n",
    "\n",
    "Here is the information,\n",
    "\n",
    "{question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Model Answer: {ground_truth}\n",
    "\n",
    "Answer A: {answer_a}\n",
    "\n",
    "Answer B: {answer_b}\n",
    "\n",
    "Answer C: {answer_c}\n",
    "\n",
    "\n",
    "\n",
    "Respond with only the JSON reply and nothing else. Use double quotes for the json schema and DO NOT use any double quotes in the values.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_two_way_template = \"\"\"Given the following question, context, and two different answers a) and b), assess the answer based on the following criteria: \n",
    " 1) factual correctness according to the context\n",
    " 2) similarity to model answer\n",
    " 3) conciseness\n",
    " \n",
    "Respond in JSON whether answer a) or b) is the better answer and state your reason using the following schema:\n",
    "\n",
    "{{\"winner\": a or b,\n",
    "\"reason\": reason it is the better answer}}\n",
    "\n",
    "Here is the information,\n",
    "\n",
    "{question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Model Answer: {ground_truth}\n",
    "\n",
    "Answer A: {answer_a}\n",
    "\n",
    "Answer B: {answer_b}\n",
    "\n",
    "Respond with only the JSON reply and nothing else. Use double quotes for the json schema and DO NOT use any double quotes in the values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [23:50<00:00,  4.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "three_way_evaluation_results = []\n",
    "gpt4_llama3_evaluation_results = []\n",
    "gpt4_gemma2_evaluation_results = []\n",
    "llama3_gemma2_evaluation_results = []\n",
    "\n",
    "\n",
    "df_eval = df_all_predictions\n",
    "for i, (index, row) in tqdm(enumerate(df_eval.iterrows()), total=len(df_eval)):\n",
    "    gpt_4_answer = row['gpt4_answer_by_hy_doc']\n",
    "    ground_truth = row['answer']\n",
    "    question = row['question']\n",
    "    hypothetical_doc = row['hypothetical_document']\n",
    "    llama3_answer = row['llama3_answer']\n",
    "    gemma2_answer = row['gemma2_answer']\n",
    "\n",
    "\n",
    "    prompt_three_way = prompt_three_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer, answer_c=gemma2_answer)\n",
    "    prompt_gpt4_llama3 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer)\n",
    "    prompt_gpt4_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=gemma2_answer)\n",
    "    prompt_llama3_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=llama3_answer, answer_b=gemma2_answer)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response_three_way = model.generate_content(prompt_three_way).text\n",
    "        response_gpt4_llama3 = model.generate_content(prompt_gpt4_llama3).text\n",
    "        response_gpt4_gemma2 = model.generate_content(prompt_gpt4_gemma2).text\n",
    "        response_llama3_gemma2 = model.generate_content(prompt_llama3_gemma2).text\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    three_way_evaluation_results.append({'gemini_flash_evaluation': response_three_way, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "    gpt4_llama3_evaluation_results.append({'gemini_flash_evaluation': response_gpt4_llama3, **row, 'llama3_answer': llama3_answer})\n",
    "    gpt4_gemma2_evaluation_results.append({'gemini_flash_evaluation': response_gpt4_gemma2, **row, 'gemma2_answer': gemma2_answer})\n",
    "    llama3_gemma2_evaluation_results.append({'gemini_flash_evaluation': response_llama3_gemma2, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(output_root_dir + subdir + '/gpt4_llama3_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in three_way_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_llama3_evaluation.jsonl', 'w') as f:\n",
    "    for l in gpt4_llama3_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in gpt4_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/llama3_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in llama3_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_inner_quotes(text):\n",
    "    split_result  = re.split(\"\\\"\\s*reason\\s*\\\"\", text, maxsplit=1)\n",
    "    winner_str = split_result[0] \n",
    "    reason_str = split_result[1][split_result[1].index('\"')+1: split_result[1].rfind('\"')].replace('\"','').replace(\"\\\\\", \"\")\n",
    "    return winner_str + \"\\\"reason\\\": \\\"\" + reason_str.strip() + '\"}'\n",
    "\n",
    "def clean_json_output(output):\n",
    "    output = output.strip()\n",
    "    if output.startswith(\"```json\"):\n",
    "        output = output[7:]\n",
    "    if output.endswith(\"```\"):\n",
    "        output = output[:-3]\n",
    "    cleaned_output = replace_inner_quotes(output.strip())\n",
    "    # cleaned_output = output.strip()\n",
    "\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(cleaned_output, strict=False)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")\n",
    "        print(cleaned_output)\n",
    "        return cleaned_output\n",
    "\n",
    "    def clean_json(data):\n",
    "        if isinstance(data, dict):\n",
    "            return {key: clean_json(value) for key, value in data.items()}\n",
    "        elif isinstance(data, list):\n",
    "            return [clean_json(item) for item in data]\n",
    "        elif isinstance(data, str):\n",
    "            return \"\" if data.lower() in [\"unknown\", \"na\", \"null\"] else data\n",
    "        else:\n",
    "            print(data)\n",
    "            return data\n",
    "    \n",
    "    cleaned_json_data = clean_json(json_data)\n",
    "    # cleaned_output = json.dumps(cleaned_json_data, ensure_ascii=False)\n",
    "\n",
    "    return cleaned_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def extract_json(text):\n",
    "#     if text.startswith(\"```json\"):\n",
    "#         found = re.findall(\"```json\\n*(.*)\\n*```\", text)\n",
    "#         try:\n",
    "#             result = json.loads(found[0])\n",
    "#         except IndexError as e:\n",
    "#             print(e, found, text)\n",
    "#     else:\n",
    "#         result = json.loads(text)        \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "for er in three_way_evaluation_results:\n",
    "    clean_json_output(er['gemini_flash_evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_way_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in three_way_evaluation_results]\n",
    "df_three_way_eval_results = pd.DataFrame(three_way_eval_json)\n",
    "df_three_way_eval_results.to_csv(output_root_dir + subdir + '/gpt4_llama3_gemma2_evaluation_outcome.csv', index=False)\n",
    "\n",
    "\n",
    "gpt4_llama3_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in gpt4_llama3_evaluation_results]\n",
    "df_gpt4_llama3_eval_results = pd.DataFrame(gpt4_llama3_eval_json)\n",
    "df_gpt4_llama3_eval_results.to_csv(output_root_dir + subdir + '/gpt4_llama3_evaluation_outcome.csv', index=False)\n",
    "\n",
    "\n",
    "gpt4_gemma2_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in gpt4_gemma2_evaluation_results]\n",
    "df_gpt4_gemma2_eval_results = pd.DataFrame(gpt4_gemma2_eval_json)\n",
    "df_gpt4_gemma2_eval_results.to_csv(output_root_dir + subdir + '/gpt4_gemma2_evaluation_outcome.csv', index=False)\n",
    "\n",
    "llama3_gemma2_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in llama3_gemma2_evaluation_results]\n",
    "df_llama3_gemma2_eval_results = pd.DataFrame(llama3_gemma2_eval_json)\n",
    "df_llama3_gemma2_eval_results.to_csv(output_root_dir + subdir + '/llama3_gemma2_evaluation_outcome.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner\n",
      "c    120\n",
      "a     96\n",
      "b     88\n",
      "Name: count, dtype: int64 winner\n",
      "b    212\n",
      "a     92\n",
      "Name: count, dtype: int64 winner\n",
      "b    221\n",
      "a     83\n",
      "Name: count, dtype: int64 winner\n",
      "b    188\n",
      "a    116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_three_way_eval_results['winner'].value_counts(),\n",
    "df_gpt4_llama3_eval_results['winner'].value_counts(),\n",
    "df_gpt4_gemma2_eval_results['winner'].value_counts(),\n",
    "df_llama3_gemma2_eval_results['winner'].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# one-shot\n",
    "\n",
    "winner\n",
    "a    126\n",
    "c    101\n",
    "b     77\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    192\n",
    "a    112\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    205\n",
    "a     99\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    218\n",
    "a     86"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# zero-shot\n",
    "\n",
    "winner\n",
    "c    120\n",
    "a     96\n",
    "b     88\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    212\n",
    "a     92\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    221\n",
    "a     83\n",
    "Name: count, dtype: int64 \n",
    "\n",
    "winner\n",
    "b    188\n",
    "a    116\n",
    "Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ragas faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_prompt_template = \"\"\"Give the following contexts, separated by ######################### and an answer, do the following:\n",
    "1. Break down the contexts into a list of statements\n",
    "2. Break down the answer into a list of statements\n",
    "3. Match the two list of statements and return the following in JSON with the following keys: \"statements_in_both\", \"statements_in_contexts_only\", \"statements_in_answer_only\"\n",
    "\n",
    "Return your answer as a JSON string in a JSON parsable format without any other output.\n",
    "\n",
    "Here are the contexts:\n",
    "{context}\n",
    "\n",
    "\n",
    "This is the answer:\n",
    "{answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/304 [00:00<00:32,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response has no candidates (and thus no text). The response is likely blocked by the safety filters.\n",
      "Response:\n",
      "{\n",
      "  \"prompt_feedback\": {\n",
      "    \"block_reason\": \"PROHIBITED_CONTENT\"\n",
      "  },\n",
      "  \"usage_metadata\": {\n",
      "    \"prompt_token_count\": 1012,\n",
      "    \"total_token_count\": 1012\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 89/304 [10:45<25:58,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "answer_key = \"llama3_answer\"\n",
    "\n",
    "faithfulness_json = []\n",
    "\n",
    "for index, row in tqdm(df_all_predictions[215:].iterrows(), total=len(df_all_predictions)):\n",
    "    answer = row[answer_key]\n",
    "    hy_doc = row['hypothetical_document']\n",
    "    faithfulness_prompt = faithfulness_prompt_template.format(answer=answer_key, context=hy_doc)\n",
    "    try:\n",
    "        response = model.generate_content(faithfulness_prompt)\n",
    "        faithfulness_json.append(response.text)\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        faithfulness_json.append(\"\\{\\\"error\\\": \" + str(ve) +\"\\}\")\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_root_dir + '/llama3_faithfulness.jsonl', 'w') as f:\n",
    "    for fj in faithfulness_json:\n",
    "        f.write(json.dumps(fj) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groq models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "groq_client = Groq(api_key=groq_api_key)\n",
    "\n",
    "def query_groq(prompt):\n",
    "    completion = groq_client.chat.completions.create(\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.01,\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    # groq_response = \"\"\n",
    "    # for chunk in completion:\n",
    "    #     # print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    #     # print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    #     response_chunk = chunk.choices[0].delta.content\n",
    "    #     if response_chunk is not None and response_chunk.strip():\n",
    "    #         groq_response +=  response_chunk + \" \"\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Assistant',\n",
       " 'address': {'street': '1234 Main St',\n",
       "  'city': 'Anytown',\n",
       "  'state': 'CA',\n",
       "  'postal_code': '12345'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_groq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<groq.Stream at 0x7f02004499a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "client = AnthropicBedrock()\n",
    "\n",
    "def query_claude3(prompt):\n",
    "    message = client.messages.create(\n",
    "        model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "        max_tokens=500,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:40<00:00, 13.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "three_way_evaluation_results_claude = []\n",
    "gpt4_llama3_evaluation_results_claude = []\n",
    "gpt4_gemma2_evaluation_results_claude = []\n",
    "llama3_gemma2_evaluation_results_claude = []\n",
    "\n",
    "df_eval = df_all_predictions\n",
    "for i, (index, row) in tqdm(enumerate(df_eval.iterrows()), total=len(df_eval)):\n",
    "    gpt_4_answer = row['gpt4_answer_by_hy_doc']\n",
    "    ground_truth = row['answer']\n",
    "    question = row['question']\n",
    "    hypothetical_doc = row['hypothetical_document']\n",
    "    llama3_answer = row['llama3_answer']\n",
    "    gemma2_answer = row['gemma2_answer']\n",
    "\n",
    "\n",
    "    prompt_three_way = prompt_three_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer, answer_c=gemma2_answer)\n",
    "    prompt_gpt4_llama3 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer)\n",
    "    prompt_gpt4_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=gemma2_answer)\n",
    "    prompt_llama3_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=llama3_answer, answer_b=gemma2_answer)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response_three_way = query_claude3(prompt_three_way)\n",
    "        response_gpt4_llama3 = query_claude3(prompt_gpt4_llama3)\n",
    "        response_gpt4_gemma2 = query_claude3(prompt_gpt4_gemma2)\n",
    "        response_llama3_gemma2 = query_claude3(prompt_llama3_gemma2)\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    three_way_evaluation_results_claude.append({'claude_evaluation': response_three_way, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "    gpt4_llama3_evaluation_results_claude.append({'claude_evaluation': response_gpt4_llama3, **row, 'llama3_answer': llama3_answer})\n",
    "    gpt4_gemma2_evaluation_results_claude.append({'claude_evaluation': response_gpt4_gemma2, **row, 'gemma2_answer': gemma2_answer})\n",
    "    llama3_gemma2_evaluation_results_claude.append({'claude_evaluation': response_llama3_gemma2, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'claude_evaluation': [TextBlock(text='{\\n\"winner\": \"b\",\\n\"reason\": \"Answer b is the better answer as it is factually correct according to the context, closely resembles the model answer, and is concise and to the point.\"\\n}', type='text')],\n",
       "  'status': 'answered',\n",
       "  'reference_answer': nan,\n",
       "  'summary_points': \"['101,464 non-voters from the 2023 Presidential Election applied to restore their names to the Registers of Electors as of end January 2024.', 'All the applications were successful.']\",\n",
       "  'points': '101,464 non-voters from the 2023 Presidential Election applied to restore their names to the Registers of Electors as of end January 2024.\\n\\nAll the applications were successful.',\n",
       "  'title': 'Applications to Restore Names to Registers of Electors',\n",
       "  'subtitle': nan,\n",
       "  'question_speaker': 'Mr Leong Mun Wai',\n",
       "  'answer_speaker': 'Mr Chan Chun Sing (for the Prime Minister)',\n",
       "  'question': 'Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.',\n",
       "  'answer': 'Mr Chan Chun Sing (for the Prime Minister): As of end January 2024, 101,464 non-voters from the 2023 Presidential Election applied to restore their names to the Registers of Electors. All the applications were successful.',\n",
       "  'filename': 'sitting_2024-02-29',\n",
       "  'hypothetical_document': \"**Title: Applications to Restore Names to Registers of Electors**\\n\\n**Executive Summary:**\\n\\nAs of the end of January 2024, a total of 101,464 non-voters from the 2023 Presidential Election have successfully applied to restore their names to the Registers of Electors. This report details the background, process, and implications of these applications, with a focus on ensuring continued electoral engagement and upholding democratic principles.\\n\\n**Background:**\\n\\nThe 2023 Presidential Election saw a significant number of eligible voters abstaining from casting their votes. Consequently, their names were removed from the Registers of Electors in accordance with established electoral regulations. However, recognizing the importance of inclusive participation in democratic processes, the Elections Department provided a mechanism for non-voters to restore their names to the registers.\\n\\n**Application Process:**\\n\\nThe process to restore names to the Registers of Electors was designed to be straightforward and accessible. Non-voters could submit their applications through various channels, including:\\n1. **Online Portal:** A dedicated section on the Elections Department's website allowed individuals to complete and submit their applications electronically.\\n2. **In-Person Submissions:** Local electoral offices across the country were equipped to handle in-person applications, ensuring access for individuals without reliable internet access.\\n3. **Mail-In Applications:** For added convenience, applicants could also restore their names via postal mail by sending completed forms to their respective electoral offices.\\n\\n**Volume of Applications:**\\n\\nBy the end of January 2024, a total of 101,464 individuals had applied to have their names restored. This significant number reflects a robust response from the public, underscoring the desire among citizens to re-engage with the electoral process. The breakdown of applications received through different channels is as follows:\\n- **Online Portal:** 67,892 applications\\n- **In-Person Submissions:** 22,710 applications\\n- **Mail-In Applications:** 10,862 applications\\n\\n**Approval and Verification:**\\n\\nAll 101,464 applications were meticulously reviewed by the Elections Department. The verification process ensured that each applicant met the criteria for restoration, including:\\n- **Verification of Identity:** Confirming the identity of applicants to prevent fraudulent submissions.\\n- **Eligibility Check:** Ensuring that applicants were eligible voters in the 2023 Presidential Election and had not been disqualified for other reasons.\\n- **Data Accuracy:** Cross-referencing application details with existing records to maintain the integrity of the Registers of Electors.\\n\\nUpon successful verification, all applications were approved, and the names of the applicants were restored to the Registers of Electors. This meticulous approach guarantees the reliability and accuracy of the electoral registers.\\n\\n**Implications:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors has several significant implications:\\n1. **Enhanced Voter Engagement:** The substantial number of restored names reflects a renewed commitment among citizens to participate in future elections, thereby strengthening democratic engagement.\\n2. **Inclusivity:** The accessible application process ensured that individuals from diverse backgrounds had the opportunity to restore their names, promoting inclusivity in the electoral process.\\n3. **Administrative Efficiency:** The Elections Department's efficient handling of the applications demonstrates its capability to manage large volumes of requests while maintaining accuracy and integrity.\\n4. **Public Trust:** The transparent and successful restoration process fosters public trust in the electoral system, reinforcing the legitimacy of future elections.\\n\\n**Conclusion:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors is a testament to the commitment of both the Elections Department and the citizens to uphold democratic values. The robust response from non-voters highlights the importance of accessible and inclusive electoral processes. Moving forward, continued efforts to engage and educate the electorate will be crucial in maintaining a vibrant and participatory democracy.\\n\\n**Recommendations:**\\n\\nTo build on this success, the following recommendations are proposed:\\n1. **Ongoing Public Awareness Campaigns:** Continuously educate the public on the importance of voting and the process for restoring names to the Registers of Electors.\\n2. **Enhanced Accessibility:** Further streamline the application process, particularly for online submissions, to accommodate an even broader segment of the population.\\n3. **Regular Updates:** Periodically update the public on the status of the Registers of Electors and any changes to the application process.\\n4. **Feedback Mechanism:** Implement a feedback mechanism to gather insights from applicants on their experience, enabling continuous improvement of the process.\\n\\nBy implementing these recommendations, we can ensure that the electoral system remains robust, inclusive, and reflective of the will of the people.\",\n",
       "  'date': '2024-02-29 00:00:00',\n",
       "  'gpt4_answer_by_hy_doc': 'As of the end of January 2024, a total of 101,464 non-voters from the 2023 Presidential Election have applied to restore their names to the Registers of Electors. All 101,464 applications have been successful.',\n",
       "  'llama3_answer': 'As at end-January 2024, there were 101,464 persons who did not vote in the last Presidential election but have since applied to restore their names to the Registers of Electors. All such applications have been approved after being verified by the Elections Department.',\n",
       "  'gemma2_answer': 'Since the close of Nomination Day for the 2023 Presidential Election, up till the end of January 2024, 101,464 non-voters who did not vote at the 2023 Presidential Election have succeeded in having their names restored onto the Registers of Electors.<|eot_id|'},\n",
       " {'claude_evaluation': [TextBlock(text='{\"winner\": \"a\", \"reason\": \"Answer A is factually correct based on the provided context, closely resembles the model answer, and is concise while covering all key points.\"}', type='text')],\n",
       "  'status': 'answered',\n",
       "  'reference_answer': nan,\n",
       "  'summary_points': \"['From 2021 to 2023, over 23,300 companies obtained financing under the Enterprise Financing Scheme (EFS).', 'More than $21 billion in loans were supported by EFS.', 'The average amount borrowed varies across different types of EFS facilities (working capital, fixed asset, and trade loans).', 'The Government does not have data on the rejection rates as EFS loans are processed by participating financial institutions.']\",\n",
       "  'points': 'From 2021 to 2023, over 23,300 companies obtained financing under the Enterprise Financing Scheme (EFS).\\n\\nMore than $21 billion in loans were supported by EFS.\\n\\nThe average amount borrowed varies across different types of EFS facilities (working capital, fixed asset, and trade loans).\\n\\nThe Government does not have data on the rejection rates as EFS loans are processed by participating financial institutions.',\n",
       "  'title': 'Applications under Enterprise Financing Scheme',\n",
       "  'subtitle': nan,\n",
       "  'question_speaker': 'Mr Liang Eng Hwa',\n",
       "  'answer_speaker': 'Mr Gan Kim Yong',\n",
       "  'question': 'Mr Liang Eng Hwa asked the Minister for Trade and Industry in the last three years (a) what is the number of companies that have obtained financing under the Enterprise Financing Scheme; (b) what is the average amount borrowed; and (c) how many applicants are unsuccessful.\\n',\n",
       "  'answer': 'Mr Gan Kim Yong: From 2021 to 2023, over 23,300 companies obtained more than $21 billion in loans supported by the Enterprise Financing Scheme (EFS). The average amount borrowed varies across the different types of EFS facilities, such as working capital, fixed asset and trade loans. As EFS loans are processed by participating financial institutions, the Government does not have data on rejection rates.',\n",
       "  'filename': 'sitting_2024-02-29',\n",
       "  'hypothetical_document': \"**Title: Applications under Enterprise Financing Scheme**\\n\\n**Introduction**\\n\\nThe Enterprise Financing Scheme (EFS) has been a cornerstone in supporting the financial needs of businesses across various sectors in our nation. As a public servant dedicated to fostering economic growth and stability, I am pleased to present a comprehensive report on the applications and outcomes of the EFS from 2021 to 2023. This report will delve into the key statistics, trends, and implications of the scheme over the past three years, highlighting its impact on the corporate landscape.\\n\\n**Overview of EFS Applications (2021-2023)**\\n\\nFrom 2021 to 2023, the Enterprise Financing Scheme has successfully facilitated financing for over 23,300 companies. This significant number underscores the critical role that the EFS has played in enabling businesses to secure the necessary funds to sustain and grow their operations. The scheme has been instrumental in addressing the varied financial needs of companies, ranging from working capital to fixed asset investments and trade financing.\\n\\n**Financial Support Under EFS**\\n\\nDuring this period, more than $21 billion in loans were supported by the EFS. This substantial figure reflects the trust and reliance that businesses have placed in the scheme. The significant financial support provided has been pivotal in ensuring that companies can navigate economic challenges, invest in growth opportunities, and maintain operational stability.\\n\\n**Variation in Average Borrowed Amounts**\\n\\nThe average amount borrowed under EFS varies significantly across different types of facilities, which include working capital loans, fixed asset loans, and trade loans. \\n\\n1. **Working Capital Loans:** These loans are designed to help businesses manage their day-to-day operations. The average amount borrowed under this facility tends to be relatively moderate, reflecting the immediate and short-term financial needs of companies. Businesses have utilized these loans to manage cash flow, pay for operational expenses, and bridge gaps between receivables and payables.\\n\\n2. **Fixed Asset Loans:** These loans are aimed at financing the purchase of long-term assets such as machinery, equipment, and real estate. The average amount borrowed in this category is generally higher than that of working capital loans, aligning with the larger capital expenditures involved. Companies have leveraged these loans to invest in assets that enhance production capabilities, improve efficiency, and expand operational capacity.\\n\\n3. **Trade Loans:** These loans facilitate international and domestic trade activities, including the import and export of goods. The average borrowed amount for trade loans varies, depending on the scale and volume of trade transactions. Such loans have enabled businesses to engage in global trade, manage supply chain dynamics, and mitigate risks associated with cross-border transactions.\\n\\n**Lack of Rejection Rate Data**\\n\\nIt is important to note that the Government does not possess data on the rejection rates of EFS loan applications. This is because the processing and approval of EFS loans are handled by participating financial institutions. These institutions assess the eligibility and creditworthiness of applicants based on their internal policies and criteria. While the lack of rejection rate data limits our ability to fully evaluate the scheme's accessibility, the high number of successful applications indicates a robust level of acceptance and support.\\n\\n**Conclusion**\\n\\nThe Enterprise Financing Scheme has demonstrably played a crucial role in supporting over 23,300 companies with more than $21 billion in loans from 2021 to 2023. The variation in average borrowed amounts across different EFS facilities highlights the diverse financial needs of businesses. Despite the absence of rejection rate data, the substantial number of successful applications attests to the scheme's effectiveness in providing essential financial support.\\n\\nAs we move forward, continuous monitoring and assessment of the EFS will be vital in ensuring its alignment with the evolving needs of businesses. The Government remains committed to fostering a conducive environment for enterprise development, and the EFS will continue to be a key instrument in achieving this objective.\\n\\n**Recommendations**\\n\\n1. **Enhanced Data Collection:** Collaborate with participating financial institutions to gather data on rejection rates to gain a more comprehensive understanding of the scheme's accessibility.\\n\\n2. **Targeted Outreach:** Implement targeted outreach programs to raise awareness about the EFS, particularly among small and medium enterprises (SMEs) that may face challenges in accessing traditional financing.\\n\\n3. **Periodic Review:** Conduct periodic reviews of the EFS to ensure that its terms and conditions remain relevant and beneficial to the changing economic landscape.\\n\\n4. **Feedback Mechanism:** Establish a feedback mechanism for businesses to provide insights and suggestions on improving the EFS, ensuring that the scheme remains responsive to their needs.\\n\\nThrough these recommendations, we can further enhance the efficacy of the Enterprise Financing Scheme and continue to support the vibrant and dynamic business ecosystem in our nation.\",\n",
       "  'date': '2024-02-29 00:00:00',\n",
       "  'gpt4_answer_by_hy_doc': 'From 2021 to 2023, over 23,300 companies have obtained financing under the Enterprise Financing Scheme (EFS). The average amount borrowed varies depending on the type of loan facility, such as working capital loans, fixed asset loans, and trade loans. The Government does not possess data on the number of unsuccessful applicants, as the processing and approval of EFS loans are handled by participating financial institutions based on their internal policies and criteria.',\n",
       "  'llama3_answer': 'From 2021 to 2023, the Enterprise Financing Scheme supported over 23,300 companies with more than $21 billion in loans. The average amount depends on the type of facility. For example, it would typically be smaller for working capital loans compared to fixed asset or trade loans. We do not reject any EFS loan applications. Hence, we do not have data on the rejection rate.',\n",
       "  'gemma2_answer': 'Between 2021 and 2023, more than 23,300 companies received financing amounting to more than $21 billion through the Enterprise Financing Scheme (EFS). On average, borrowers took up around $950,000 per company across all EFS facilities. However, the average amount borrowed could vary across different types of EFS facilities – working capital loans tend to be smaller compared to fixed asset or trade loans. We do not have information on the rejection rate of EFS loan applications, as the Government does not extend direct loans but instead provides risk sharing support to Participating Financial Institutions who make the final decision on whether to approve an application.<|eot_id|'},\n",
       " {'claude_evaluation': [TextBlock(text='{\"winner\": \"a\", \"reason\": \"Answer a) provides the most concise and direct response to the three sub-questions asked, covering the number of companies that obtained grants, the average grant amount, and the high approval rate (implying a low number of unsuccessful applicants). It aligns closely with the key details presented in the context and the model answer.\"}', type='text')],\n",
       "  'status': 'answered',\n",
       "  'reference_answer': nan,\n",
       "  'summary_points': \"['About 36,400 companies have received support under the Productivity Solutions Grant (PSG) in the last three years.', 'The average amount of grant awarded was about $6,600 per project.', 'Close to 95% of all complete submissions were approved.']\",\n",
       "  'points': 'About 36,400 companies have received support under the Productivity Solutions Grant (PSG) in the last three years.\\n\\nThe average amount of grant awarded was about $6,600 per project.\\n\\nClose to 95% of all complete submissions were approved.',\n",
       "  'title': 'Applications for Productivity Solutions Grant in Last Three Years',\n",
       "  'subtitle': nan,\n",
       "  'question_speaker': 'Mr Liang Eng Hwa',\n",
       "  'answer_speaker': 'Mr Gan Kim Yong',\n",
       "  'question': 'Mr Liang Eng Hwa asked the Minister for Trade and Industry (a) what is the number of companies that have obtained grants under the Productivity Solutions Grant in the last three years; (b) what is the average amount of grant awarded; and (c) how many applicants are unsuccessful.',\n",
       "  'answer': 'Mr Gan Kim Yong: In the last three years, about 36,400 companies have received support under the Productivity Solutions Grant (PSG). The average quantum of support for PSG was about $6,600 per project. Close to 95% of all complete submissions were approved.',\n",
       "  'filename': 'sitting_2024-02-29',\n",
       "  'hypothetical_document': \"### Applications for Productivity Solutions Grant in Last Three Years\\n\\n#### Executive Summary\\nThis report aims to provide a comprehensive analysis of the applications and approvals for the Productivity Solutions Grant (PSG) over the past three years. The PSG is a government initiative designed to support businesses in adopting IT solutions and equipment to improve productivity. The data reflects the success of the program in fostering technological advancements among small and medium-sized enterprises (SMEs).\\n\\n#### Overview of PSG Applications and Approvals\\n\\nOver the last three years, approximately 36,400 companies have benefited from the Productivity Solutions Grant. The PSG has been instrumental in enabling businesses to enhance their operational efficiency through the adoption of various productivity solutions.\\n\\n#### Financial Impact\\n\\nOn average, each project received a grant amount of about $6,600. This financial support has empowered companies to invest in technology and equipment that they might have otherwise found prohibitively expensive. The relatively modest average grant amount suggests that the PSG is accessible and beneficial to a wide range of businesses, particularly SMEs.\\n\\n#### Approval Rate\\n\\nThe grant program has a high approval rate, with close to 95% of all complete submissions being approved. This high approval rate indicates that the PSG application process is well-structured and that the majority of applicants meet the eligibility criteria. It also reflects the government's commitment to supporting businesses in their productivity enhancement endeavors.\\n\\n#### Sectoral Distribution\\n\\nAn analysis of the sectoral distribution of the grants reveals that companies from diverse industries have applied for and received PSG support. The sectors range from manufacturing and logistics to retail and professional services. This wide-ranging adoption underscores the flexibility and applicability of the PSG across different business contexts.\\n\\n#### Case Studies\\n\\nTo illustrate the tangible benefits of the PSG, this report includes two case studies:\\n\\n1. **Tech Solutions Ltd.** - A small IT firm that received a PSG grant to implement a new project management software. The software streamlined their operations, reducing project delivery times by 25% and increasing client satisfaction rates.\\n\\n2. **Green Grocers** - A mid-sized retail business that used the PSG to upgrade their inventory management system. This upgrade led to a 30% reduction in stock wastage and a 20% increase in sales due to better stock availability.\\n\\n#### Challenges Encountered\\n\\nWhile the PSG has been largely successful, a few challenges were noted:\\n\\n- **Awareness and Outreach:** Some businesses, particularly smaller ones, were initially unaware of the PSG and its benefits.\\n- **Application Process:** Although the approval rate is high, a segment of applicants found the submission process somewhat cumbersome, indicating a need for further simplification.\\n\\n#### Recommendations\\n\\nBased on the analysis, the following recommendations are proposed:\\n\\n1. **Enhanced Outreach Programs:** Increase awareness through targeted campaigns, especially in underrepresented sectors.\\n2. **Streamline Application Process:** Simplify the application procedures to make it even more accessible to small businesses.\\n3. **Post-Grant Support:** Provide additional resources and support for grant recipients to maximize the impact of their new technology and equipment.\\n\\n#### Conclusion\\n\\nThe Productivity Solutions Grant has proven to be a valuable tool in driving productivity improvements across a broad spectrum of industries. The high approval rate and the substantial number of companies benefiting from the grant underscore its success. By addressing the noted challenges and implementing the recommended improvements, the PSG can continue to play a crucial role in enhancing the productivity and competitiveness of businesses in our economy.\\n\\n#### Appendices\\n\\n- **Appendix A:** Detailed Statistics on PSG Applications and Approvals\\n- **Appendix B:** Sectoral Distribution of PSG Grants\\n- **Appendix C:** Case Study Details\\n\\nPrepared by: [Your Name]  \\nPosition: [Your Position]  \\nDate: [Today's Date]\",\n",
       "  'date': '2024-02-29 00:00:00',\n",
       "  'gpt4_answer_by_hy_doc': 'Over the last three years, approximately 36,400 companies have obtained grants under the Productivity Solutions Grant. On average, each project received a grant amount of about $6,600. The grant program has a high approval rate, with close to 95% of all complete submissions being approved, indicating that the number of unsuccessful applicants is relatively low.',\n",
       "  'llama3_answer': 'In the last three years, almost 36,400 companies adopted the Productivity Solutions Grant (PSG). Each company would typically adopt multiple projects. On average, each project was granted an average of about $6,600. About nine in 10 companies who submitted a complete application were approved. Companies span across virtually every industry, including wholesale trade, retail, food services, information and communications, finance and insurance, as well as professional services.',\n",
       "  'gemma2_answer': 'In the last three years, around 36,400 companies had projects supported under the Productivity Solutions Grant (PSG), with an average grant of around $6,600 per project. Close to 95% of complete submissions would be approved for funding.<|eot_id|'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_way_evaluation_results_claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open(output_root_dir + subdir + '/gpt4_llama3_gemma2_evaluation_mixtral.jsonl', 'w') as f:\n",
    "#     for l in three_way_evaluation_results:\n",
    "#         f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "# with open(output_root_dir + subdir + '/gpt4_llama3_evaluation_mixtral.jsonl', 'w') as f:\n",
    "#     for l in gpt4_llama3_evaluation_results:\n",
    "#         f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_gemma2_evaluation_mixtral.jsonl', 'w') as f:\n",
    "    for l in gpt4_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/llama3_gemma2_evaluation_mixtral.jsonl', 'w') as f:\n",
    "    for l in llama3_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "llama3_mixtral_eval = [re.findall(\"\\\"winner\\\": \\\"(\\w)\\\"\", er['mixtral_evaluation']) for er in eval_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    256\n",
       "b     36\n",
       "A      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(llama3_mixtral_eval).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
