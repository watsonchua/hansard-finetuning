{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"google-cloud-aiplatform>=1.38\" vertexai\n",
    "#TODO: gcloud auth application-default login to authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "project_id = \"gvt0031-gcp-152-govtext-ds\"\n",
    "\n",
    "vertexai.init(project=project_id, location=\"asia-southeast1\")\n",
    "\n",
    "model = GenerativeModel(model_name=\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_predictions_path = \"/home/watson_chua/efs/axolotl/data/predictions/hansard/llama3_8b_lora.jsonl\"\n",
    "gemma_predictions_path = \"/home/watson_chua/efs/axolotl/data/predictions/hansard/gemma2_9b_lora.jsonl\"\n",
    "# gpt4_predictions_path = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc.jsonl\"\n",
    "gpt4_predictions_path = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc_concise.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(llama_predictions_path, 'r') as f:\n",
    "    llama_lines = f.readlines()\n",
    "\n",
    "with open(gemma_predictions_path, 'r') as f:\n",
    "    gemma_lines = f.readlines()\n",
    "\n",
    "with open(gpt4_predictions_path, 'r') as f:\n",
    "    gpt4_lines = f.readlines()\n",
    "\n",
    "llama_lines = [json.loads(l) for l in llama_lines]\n",
    "gemma_lines = [json.loads(l) for l in gemma_lines]\n",
    "gpt4_lines = [json.loads(l) for l in gpt4_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 304, 304)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_lines), len(gemma_lines), len(gpt4_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation': 'As at end-January 2024, there were 101,464 persons who did not vote in the last Presidential election but have since applied to restore their names to the Registers of Electors. All such applications have been approved after being verified by the Elections Department.',\n",
       " 'input': \"<|start_header_id|>system<|end_header_id|>You are a public servant. Your task is to reply to a parliamentary question given a list of supporting points.<|eot_id|><|start_header_id|>user<|end_header_id|>\\nQuestion:Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.\\n\\nSupporting points: **Title: Applications to Restore Names to Registers of Electors**\\n\\n**Executive Summary:**\\n\\nAs of the end of January 2024, a total of 101,464 non-voters from the 2023 Presidential Election have successfully applied to restore their names to the Registers of Electors. This report details the background, process, and implications of these applications, with a focus on ensuring continued electoral engagement and upholding democratic principles.\\n\\n**Background:**\\n\\nThe 2023 Presidential Election saw a significant number of eligible voters abstaining from casting their votes. Consequently, their names were removed from the Registers of Electors in accordance with established electoral regulations. However, recognizing the importance of inclusive participation in democratic processes, the Elections Department provided a mechanism for non-voters to restore their names to the registers.\\n\\n**Application Process:**\\n\\nThe process to restore names to the Registers of Electors was designed to be straightforward and accessible. Non-voters could submit their applications through various channels, including:\\n1. **Online Portal:** A dedicated section on the Elections Department's website allowed individuals to complete and submit their applications electronically.\\n2. **In-Person Submissions:** Local electoral offices across the country were equipped to handle in-person applications, ensuring access for individuals without reliable internet access.\\n3. **Mail-In Applications:** For added convenience, applicants could also restore their names via postal mail by sending completed forms to their respective electoral offices.\\n\\n**Volume of Applications:**\\n\\nBy the end of January 2024, a total of 101,464 individuals had applied to have their names restored. This significant number reflects a robust response from the public, underscoring the desire among citizens to re-engage with the electoral process. The breakdown of applications received through different channels is as follows:\\n- **Online Portal:** 67,892 applications\\n- **In-Person Submissions:** 22,710 applications\\n- **Mail-In Applications:** 10,862 applications\\n\\n**Approval and Verification:**\\n\\nAll 101,464 applications were meticulously reviewed by the Elections Department. The verification process ensured that each applicant met the criteria for restoration, including:\\n- **Verification of Identity:** Confirming the identity of applicants to prevent fraudulent submissions.\\n- **Eligibility Check:** Ensuring that applicants were eligible voters in the 2023 Presidential Election and had not been disqualified for other reasons.\\n- **Data Accuracy:** Cross-referencing application details with existing records to maintain the integrity of the Registers of Electors.\\n\\nUpon successful verification, all applications were approved, and the names of the applicants were restored to the Registers of Electors. This meticulous approach guarantees the reliability and accuracy of the electoral registers.\\n\\n**Implications:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors has several significant implications:\\n1. **Enhanced Voter Engagement:** The substantial number of restored names reflects a renewed commitment among citizens to participate in future elections, thereby strengthening democratic engagement.\\n2. **Inclusivity:** The accessible application process ensured that individuals from diverse backgrounds had the opportunity to restore their names, promoting inclusivity in the electoral process.\\n3. **Administrative Efficiency:** The Elections Department's efficient handling of the applications demonstrates its capability to manage large volumes of requests while maintaining accuracy and integrity.\\n4. **Public Trust:** The transparent and successful restoration process fosters public trust in the electoral system, reinforcing the legitimacy of future elections.\\n\\n**Conclusion:**\\n\\nThe successful restoration of 101,464 names to the Registers of Electors is a testament to the commitment of both the Elections Department and the citizens to uphold democratic values. The robust response from non-voters highlights the importance of accessible and inclusive electoral processes. Moving forward, continued efforts to engage and educate the electorate will be crucial in maintaining a vibrant and participatory democracy.\\n\\n**Recommendations:**\\n\\nTo build on this success, the following recommendations are proposed:\\n1. **Ongoing Public Awareness Campaigns:** Continuously educate the public on the importance of voting and the process for restoring names to the Registers of Electors.\\n2. **Enhanced Accessibility:** Further streamline the application process, particularly for online submissions, to accommodate an even broader segment of the population.\\n3. **Regular Updates:** Periodically update the public on the status of the Registers of Electors and any changes to the application process.\\n4. **Feedback Mechanism:** Implement a feedback mechanism to gather insights from applicants on their experience, enabling continuous improvement of the process.\\n\\nBy implementing these recommendations, we can ensure that the electoral system remains robust, inclusive, and reflective of the will of the people.\\n\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_lines[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr Leong Mun Wai asked the Prime Minister (a) since the conclusion of the 2023 Presidential Election, how many non-voters have applied to restore their names to the Registers of Electors; and (b) how many of these applications are successful.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_lines[0]['input'].split(\"<|end_header_id|>\\nQuestion:\", maxsplit=1)[-1].split(\"\\n\\nSupporting points:\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_questions = [q['input'].split(\"<|end_header_id|>\\nQuestion:\", maxsplit=1)[-1].split(\"\\n\\nSupporting points:\")[0] for q in llama_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(gpt4_lines):\n",
    "    if l['question'] not in llama_questions:\n",
    "        print(i, l['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_gpt4 = pd.DataFrame(gpt4_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated = df_gpt4[df_gpt4['question'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4_deduplicated = df_gpt4.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>summary_points</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>question_speaker</th>\n",
       "      <th>answer_speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>filename</th>\n",
       "      <th>hypothetical_document</th>\n",
       "      <th>date</th>\n",
       "      <th>gpt4_answer_by_hy_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[101,464 non-voters from the 2023 Presidential...</td>\n",
       "      <td>101,464 non-voters from the 2023 Presidential ...</td>\n",
       "      <td>Applications to Restore Names to Registers of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chan Chun Sing (for the Prime Minister)</td>\n",
       "      <td>Mr Leong Mun Wai asked the Prime Minister (a) ...</td>\n",
       "      <td>Mr Chan Chun Sing (for the Prime Minister): As...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Applications to Restore Names to Regi...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Title: Applications to Restore Names to Regist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[From 2021 to 2023, over 23,300 companies obta...</td>\n",
       "      <td>From 2021 to 2023, over 23,300 companies obtai...</td>\n",
       "      <td>Applications under Enterprise Financing Scheme</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Liang Eng Hwa</td>\n",
       "      <td>Mr Gan Kim Yong</td>\n",
       "      <td>Mr Liang Eng Hwa asked the Minister for Trade ...</td>\n",
       "      <td>Mr Gan Kim Yong: From 2021 to 2023, over 23,30...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Applications under Enterprise Financi...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>### Applications under Enterprise Financing Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[About 36,400 companies have received support ...</td>\n",
       "      <td>About 36,400 companies have received support u...</td>\n",
       "      <td>Applications for Productivity Solutions Grant ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Liang Eng Hwa</td>\n",
       "      <td>Mr Gan Kim Yong</td>\n",
       "      <td>Mr Liang Eng Hwa asked the Minister for Trade ...</td>\n",
       "      <td>Mr Gan Kim Yong: In the last three years, abou...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>### Applications for Productivity Solutions Gr...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Title: Applications for Productivity Solutions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[Schools have autonomy to decide the end times...</td>\n",
       "      <td>Schools have autonomy to decide the end times ...</td>\n",
       "      <td>Time Guidelines for Schools to Cease Co-curric...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chan Chun Sing</td>\n",
       "      <td>Mr Leong Mun Wai asked the Minister for Educat...</td>\n",
       "      <td>Mr Chan Chun Sing: Schools have the autonomy t...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Title: Time Guidelines for Schools to Cease ...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Title: Time Guidelines for Schools to Cease Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answered</td>\n",
       "      <td></td>\n",
       "      <td>[Rail operators have improved track design and...</td>\n",
       "      <td>Rail operators have improved track design and ...</td>\n",
       "      <td>Mitigation Measures to Reduce Noise from Railw...</td>\n",
       "      <td>None</td>\n",
       "      <td>Mr Leong Mun Wai</td>\n",
       "      <td>Mr Chee Hong Tat</td>\n",
       "      <td>Mr Leong Mun Wai asked the Minister for Transp...</td>\n",
       "      <td>Over the years, rail operators have improved t...</td>\n",
       "      <td>sitting_2024-02-29</td>\n",
       "      <td>**Report: Mitigation Measures to Reduce Noise ...</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>Title: Mitigation Measures to Reduce Noise fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status reference_answer  \\\n",
       "0  answered                    \n",
       "1  answered                    \n",
       "2  answered                    \n",
       "3  answered                    \n",
       "4  answered                    \n",
       "\n",
       "                                      summary_points  \\\n",
       "0  [101,464 non-voters from the 2023 Presidential...   \n",
       "1  [From 2021 to 2023, over 23,300 companies obta...   \n",
       "2  [About 36,400 companies have received support ...   \n",
       "3  [Schools have autonomy to decide the end times...   \n",
       "4  [Rail operators have improved track design and...   \n",
       "\n",
       "                                              points  \\\n",
       "0  101,464 non-voters from the 2023 Presidential ...   \n",
       "1  From 2021 to 2023, over 23,300 companies obtai...   \n",
       "2  About 36,400 companies have received support u...   \n",
       "3  Schools have autonomy to decide the end times ...   \n",
       "4  Rail operators have improved track design and ...   \n",
       "\n",
       "                                               title subtitle  \\\n",
       "0  Applications to Restore Names to Registers of ...     None   \n",
       "1     Applications under Enterprise Financing Scheme     None   \n",
       "2  Applications for Productivity Solutions Grant ...     None   \n",
       "3  Time Guidelines for Schools to Cease Co-curric...     None   \n",
       "4  Mitigation Measures to Reduce Noise from Railw...     None   \n",
       "\n",
       "   question_speaker                              answer_speaker  \\\n",
       "0  Mr Leong Mun Wai  Mr Chan Chun Sing (for the Prime Minister)   \n",
       "1  Mr Liang Eng Hwa                             Mr Gan Kim Yong   \n",
       "2  Mr Liang Eng Hwa                             Mr Gan Kim Yong   \n",
       "3  Mr Leong Mun Wai                           Mr Chan Chun Sing   \n",
       "4  Mr Leong Mun Wai                            Mr Chee Hong Tat   \n",
       "\n",
       "                                            question  \\\n",
       "0  Mr Leong Mun Wai asked the Prime Minister (a) ...   \n",
       "1  Mr Liang Eng Hwa asked the Minister for Trade ...   \n",
       "2  Mr Liang Eng Hwa asked the Minister for Trade ...   \n",
       "3  Mr Leong Mun Wai asked the Minister for Educat...   \n",
       "4  Mr Leong Mun Wai asked the Minister for Transp...   \n",
       "\n",
       "                                              answer            filename  \\\n",
       "0  Mr Chan Chun Sing (for the Prime Minister): As...  sitting_2024-02-29   \n",
       "1  Mr Gan Kim Yong: From 2021 to 2023, over 23,30...  sitting_2024-02-29   \n",
       "2  Mr Gan Kim Yong: In the last three years, abou...  sitting_2024-02-29   \n",
       "3  Mr Chan Chun Sing: Schools have the autonomy t...  sitting_2024-02-29   \n",
       "4  Over the years, rail operators have improved t...  sitting_2024-02-29   \n",
       "\n",
       "                               hypothetical_document                 date  \\\n",
       "0  **Title: Applications to Restore Names to Regi...  2024-02-29 00:00:00   \n",
       "1  **Title: Applications under Enterprise Financi...  2024-02-29 00:00:00   \n",
       "2  ### Applications for Productivity Solutions Gr...  2024-02-29 00:00:00   \n",
       "3  **Title: Time Guidelines for Schools to Cease ...  2024-02-29 00:00:00   \n",
       "4  **Report: Mitigation Measures to Reduce Noise ...  2024-02-29 00:00:00   \n",
       "\n",
       "                               gpt4_answer_by_hy_doc  \n",
       "0  Title: Applications to Restore Names to Regist...  \n",
       "1  ### Applications under Enterprise Financing Sc...  \n",
       "2  Title: Applications for Productivity Solutions...  \n",
       "3  Title: Time Guidelines for Schools to Cease Co...  \n",
       "4  Title: Mitigation Measures to Reduce Noise fro...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4_deduplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (index, row) in enumerate(df_gpt4_deduplicated.iterrows()):\n",
    "    if row['question'] != llama_questions[i]:\n",
    "        print(row['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_three_way_template = \"\"\"Given the following question, context, and three different answers a), b) and c), assess the answer based on the following criteria: \n",
    " 1) factual correctness according to the context\n",
    " 2) similarity to model answer\n",
    " 3) conciseness\n",
    " \n",
    "Respond in JSON whether answer a), b), or c) is the better answer and state your reason using the following schema:\n",
    "\n",
    "{{\"winner\": a, b, or c,\n",
    "\"reason\": reason it is the better answer}}\n",
    "\n",
    "Here is the information,\n",
    "\n",
    "{question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Model Answer: {ground_truth}\n",
    "\n",
    "Answer A: {answer_a}\n",
    "\n",
    "Answer B: {answer_b}\n",
    "\n",
    "Answer C: {answer_c}\n",
    "\n",
    "\n",
    "\n",
    "Respond with only the JSON reply and nothing else. Use double quotes for the json schema and DO NOT use any double quotes in the values.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_two_way_template = \"\"\"Given the following question, context, and two different answers a) and b), assess the answer based on the following criteria: \n",
    " 1) factual correctness according to the context\n",
    " 2) similarity to model answer\n",
    " 3) conciseness\n",
    " \n",
    "Respond in JSON whether answer a) or b) is the better answer and state your reason using the following schema:\n",
    "\n",
    "{{\"winner\": a or b,\n",
    "\"reason\": reason it is the better answer}}\n",
    "\n",
    "Here is the information,\n",
    "\n",
    "{question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Model Answer: {ground_truth}\n",
    "\n",
    "Answer A: {answer_a}\n",
    "\n",
    "Answer B: {answer_b}\n",
    "\n",
    "Respond with only the JSON reply and nothing else. Use double quotes for the json schema and DO NOT use any double quotes in the values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [24:26<00:00,  4.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "three_way_evaluation_results = []\n",
    "gpt4_llama3_evaluation_results = []\n",
    "gpt4_gemma2_evaluation_results = []\n",
    "llama3_gemma2_evaluation_results = []\n",
    "\n",
    "\n",
    "df_eval = df_gpt4_deduplicated\n",
    "for i, (index, row) in tqdm(enumerate(df_eval.iterrows()), total=len(df_eval)):\n",
    "    gpt_4_answer = row['gpt4_answer_by_hy_doc']\n",
    "    ground_truth = row['answer']\n",
    "    question = row['question']\n",
    "    hypothetical_doc = row['hypothetical_document']\n",
    "    llama3_answer = llama_lines[i]['generation']\n",
    "    gemma2_answer = gemma_lines[i]['generation']\n",
    "\n",
    "\n",
    "    prompt_three_way = prompt_three_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer, answer_c=gemma2_answer)\n",
    "    prompt_gpt4_llama3 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=llama3_answer)\n",
    "    prompt_gpt4_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=gpt_4_answer, answer_b=gemma2_answer)\n",
    "    prompt_llama3_gemma2 = prompt_two_way_template.format(context=hypothetical_doc, ground_truth=ground_truth, question=question, answer_a=llama3_answer, answer_b=gemma2_answer)\n",
    "\n",
    "\n",
    "    try:\n",
    "        response_three_way = model.generate_content(prompt_three_way).text\n",
    "        response_gpt4_llama3 = model.generate_content(prompt_gpt4_llama3).text\n",
    "        response_gpt4_gemma2 = model.generate_content(prompt_gpt4_gemma2).text\n",
    "        response_llama3_gemma2 = model.generate_content(prompt_llama3_gemma2).text\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    three_way_evaluation_results.append({'gemini_flash_evaluation': response_three_way, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "    gpt4_llama3_evaluation_results.append({'gemini_flash_evaluation': response_gpt4_llama3, **row, 'llama3_answer': llama3_answer})\n",
    "    gpt4_gemma2_evaluation_results.append({'gemini_flash_evaluation': response_gpt4_gemma2, **row, 'gemma2_answer': gemma2_answer})\n",
    "    llama3_gemma2_evaluation_results.append({'gemini_flash_evaluation': response_llama3_gemma2, **row, 'llama3_answer': llama3_answer, 'gemma2_answer': gemma2_answer})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root_dir = '/home/watson_chua/efs/axolotl/data/evaluations/hansard/'\n",
    "subdir = 'gpt4_concise'\n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_llama3_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in three_way_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_llama3_evaluation.jsonl', 'w') as f:\n",
    "    for l in gpt4_llama3_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/gpt4_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in gpt4_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  \n",
    "\n",
    "with open(output_root_dir + subdir + '/llama3_gemma2_evaluation.jsonl', 'w') as f:\n",
    "    for l in llama3_gemma2_evaluation_results:\n",
    "        f.write(json.dumps(l) + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "json.loads('\\\\\\\"hello\\\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_inner_quotes(text):\n",
    "    split_result  = re.split(\"\\\"\\s*reason\\s*\\\"\", text, maxsplit=1)\n",
    "    winner_str = split_result[0] \n",
    "    reason_str = split_result[1][split_result[1].index('\"')+1: split_result[1].rfind('\"')].replace('\"','').replace(\"\\\\\", \"\")\n",
    "    return winner_str + \"\\\"reason\\\": \\\"\" + reason_str.strip() + '\"}'\n",
    "\n",
    "def clean_json_output(output):\n",
    "    output = output.strip()\n",
    "    if output.startswith(\"```json\"):\n",
    "        output = output[7:]\n",
    "    if output.endswith(\"```\"):\n",
    "        output = output[:-3]\n",
    "    cleaned_output = replace_inner_quotes(output.strip())\n",
    "    # cleaned_output = output.strip()\n",
    "\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(cleaned_output)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decoding error: {e}\")\n",
    "        print(cleaned_output)\n",
    "        return cleaned_output\n",
    "\n",
    "    def clean_json(data):\n",
    "        if isinstance(data, dict):\n",
    "            return {key: clean_json(value) for key, value in data.items()}\n",
    "        elif isinstance(data, list):\n",
    "            return [clean_json(item) for item in data]\n",
    "        elif isinstance(data, str):\n",
    "            return \"\" if data.lower() in [\"unknown\", \"na\", \"null\"] else data\n",
    "        else:\n",
    "            print(data)\n",
    "            return data\n",
    "    \n",
    "    cleaned_json_data = clean_json(json_data)\n",
    "    # cleaned_output = json.dumps(cleaned_json_data, ensure_ascii=False)\n",
    "\n",
    "    return cleaned_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# def extract_json(text):\n",
    "#     if text.startswith(\"```json\"):\n",
    "#         found = re.findall(\"```json\\n*(.*)\\n*```\", text)\n",
    "#         try:\n",
    "#             result = json.loads(found[0])\n",
    "#         except IndexError as e:\n",
    "#             print(e, found, text)\n",
    "#     else:\n",
    "#         result = json.loads(text)        \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for er in three_way_evaluation_results:\n",
    "    clean_json_output(er['gemini_flash_evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_way_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in three_way_evaluation_results]\n",
    "df_three_way_eval_results = pd.DataFrame(three_way_eval_json)\n",
    "df_three_way_eval_results.to_csv(output_root_dir + subdir + '/gpt4_llama3_gemma2_evaluation_outcome.csv', index=False)\n",
    "\n",
    "\n",
    "gpt4_llama3_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in gpt4_llama3_evaluation_results]\n",
    "df_gpt4_llama3_eval_results = pd.DataFrame(gpt4_llama3_eval_json)\n",
    "df_gpt4_llama3_eval_results.to_csv(output_root_dir + subdir + '/gpt4_llama3_evaluation_outcome.csv', index=False)\n",
    "\n",
    "\n",
    "gpt4_gemma2_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in gpt4_gemma2_evaluation_results]\n",
    "df_gpt4_gemma2_eval_results = pd.DataFrame(gpt4_gemma2_eval_json)\n",
    "df_gpt4_gemma2_eval_results.to_csv(output_root_dir + subdir + '/gpt4_gemma2_evaluation_outcome.csv', index=False)\n",
    "\n",
    "llama3_gemma2_eval_json = [clean_json_output(er['gemini_flash_evaluation']) for er in llama3_gemma2_evaluation_results]\n",
    "df_llama3_gemma2_eval_results = pd.DataFrame(llama3_gemma2_eval_json)\n",
    "df_llama3_gemma2_eval_results.to_csv(output_root_dir + subdir + '/llama3_gemma2_evaluation_outcome.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner\n",
      "b    129\n",
      "c     99\n",
      "a     76\n",
      "Name: count, dtype: int64 winner\n",
      "b    262\n",
      "a     42\n",
      "Name: count, dtype: int64 winner\n",
      "b    269\n",
      "a     35\n",
      "Name: count, dtype: int64 winner\n",
      "b    201\n",
      "a    103\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_three_way_eval_results['winner'].value_counts(),\n",
    "df_gpt4_llama3_eval_results['winner'].value_counts(),\n",
    "df_gpt4_gemma2_eval_results['winner'].value_counts(),\n",
    "df_llama3_gemma2_eval_results['winner'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner\n",
       "b    191\n",
       "a    113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama3_gemma2_eval_results['winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
