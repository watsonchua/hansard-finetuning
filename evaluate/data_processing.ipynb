{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file which llama3 and gemma2 predictions are written to\n",
    "predictions_root_dir = '/home/watson_chua/efs/axolotl/data/predictions/hansard/'\n",
    "llama_predictions_path = predictions_root_dir + \"llama3_8b_lora.jsonl\"\n",
    "gemma_predictions_path = predictions_root_dir + \"gemma2_9b_lora.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle between these two lines to get the gpt4 predictions for zero shot and one shot\n",
    "\n",
    "# gpt4_predictions_path, out_subdir = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc.jsonl\", 'gpt4_normal'\n",
    "gpt4_predictions_path, out_subdir = \"/home/watson_chua/efs/axolotl/data/input_data/data/gpt4_answers_by_hy_doc_concise.jsonl\", 'gpt4_concise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(llama_predictions_path, 'r') as f:\n",
    "    llama_lines = f.readlines()\n",
    "\n",
    "with open(gemma_predictions_path, 'r') as f:\n",
    "    gemma_lines = f.readlines()\n",
    "\n",
    "with open(gpt4_predictions_path, 'r') as f:\n",
    "    gpt4_lines = f.readlines()\n",
    "\n",
    "llama_lines = [json.loads(l) for l in llama_lines]\n",
    "gemma_lines = [json.loads(l) for l in gemma_lines]\n",
    "gpt4_lines = [json.loads(l) for l in gpt4_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 304, 304)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_lines), len(gemma_lines), len(gpt4_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_gpt4 = pd.DataFrame(gpt4_lines)\n",
    "df_gpt4_deduplicated = df_gpt4.drop_duplicates('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_predictions = df_gpt4_deduplicated.copy()\n",
    "df_all_predictions['llama3_answer'] = [l['generation']  for l in llama_lines]\n",
    "df_all_predictions['gemma2_answer'] = [l['generation']  for l in gemma_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root_dir = '/home/watson_chua/efs/axolotl/data/evaluations/hansard/'\n",
    "df_all_predictions.to_csv(output_root_dir + out_subdir + '/consolidated_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
